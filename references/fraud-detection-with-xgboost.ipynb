{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11234331,"sourceType":"datasetVersion","datasetId":7018088}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"sahideseker/fraud-detection-in-transactions-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T01:58:52.586416Z","iopub.execute_input":"2025-04-15T01:58:52.586676Z","iopub.status.idle":"2025-04-15T01:58:52.773803Z","shell.execute_reply.started":"2025-04-15T01:58:52.586657Z","shell.execute_reply":"2025-04-15T01:58:52.773098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# ====== 1. Load Data ======\ndf = pd.read_csv(\"/kaggle/input/fraud-detection-in-transactions-dataset/fraud_detection.csv\")  # Ganti dengan nama file kamu\nprint(f\"üìä Dataset loaded: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n\n# ====== 2. Basic Info ======\nprint(\"\\nüìã Basic Info:\")\nprint(df.info())\n\n# ====== 3. Missing Values & Duplicate Rows Check ======\nprint(\"\\nüîç Missing Values:\")\nmissing = df.isnull().sum()\nprint(missing[missing > 0])\n\nprint(\"\\nüîç Duplicate Rows:\")\nduplicate = df.duplicated().sum()\nprint(duplicate)\n\n# ====== 4. Skewness Check ======\nprint(\"\\nüìà Skewness Check:\")\nskewed_features = df.select_dtypes(include=['number']).apply(lambda x: x.skew()).sort_values(ascending=False)\nprint(skewed_features)\n\nprint(\"\\nüìå Recommendation:\")\nfor col, skew in skewed_features.items():\n    if abs(skew) > 1:\n        print(f\"‚ö†Ô∏è {col} is highly skewed (skew={skew:.2f}). Suggest: Apply log or sqrt transform.\")\n    elif abs(skew) > 0.5:\n        print(f\"‚ÑπÔ∏è {col} is moderately skewed (skew={skew:.2f}). Transform optional.\")\n    else:\n        print(f\"‚úÖ {col} is fairly symmetric (skew={skew:.2f}). No action needed.\")\n\n# ====== 5. Outlier Detection (IQR Method) ======\nprint(\"\\nüì¶ Outlier Check (IQR Method):\")\nfor col in df.select_dtypes(include=['number']):\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    outlier_count = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()\n    if outlier_count > 0:\n        print(f\"‚ö†Ô∏è {col}: {outlier_count} outliers detected.\")\n    else:\n        print(f\"‚úÖ {col}: No significant outliers.\")\n\n# ====== 6. Correlation Analysis ======\nprint(\"\\nüîó Correlation Matrix (Top correlated pairs):\")\ncorrelation = df.corr(numeric_only=True)\ncor_matrix = correlation.abs().unstack().sort_values(ascending=False).drop_duplicates()\ntop_corr = cor_matrix[(cor_matrix < 1) & (cor_matrix > 0.7)]\nprint(top_corr)\n\nprint(\"\\nüìå Recommendation:\")\nfor (f1, f2), corr_val in top_corr.items():\n    print(f\"‚ö†Ô∏è {f1} & {f2} have high correlation ({corr_val:.2f}). Suggest: Keep only one or apply dimensionality reduction (e.g., PCA).\")\n\n# ====== 7. Heatmap ======\nplt.figure(figsize=(10, 6))\nsns.heatmap(correlation, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.title(\"Correlation Heatmap\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T01:58:52.774935Z","iopub.execute_input":"2025-04-15T01:58:52.775152Z","iopub.status.idle":"2025-04-15T01:58:52.956066Z","shell.execute_reply.started":"2025-04-15T01:58:52.775132Z","shell.execute_reply":"2025-04-15T01:58:52.954952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T01:58:52.956623Z","iopub.execute_input":"2025-04-15T01:58:52.956858Z","iopub.status.idle":"2025-04-15T01:58:52.966190Z","shell.execute_reply.started":"2025-04-15T01:58:52.956841Z","shell.execute_reply":"2025-04-15T01:58:52.965167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocessing Transform\nimport numpy as np\ndf['amount_log'] = np.log1p(df['amount'])  # log transform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T01:58:52.967826Z","iopub.execute_input":"2025-04-15T01:58:52.968279Z","iopub.status.idle":"2025-04-15T01:58:52.980818Z","shell.execute_reply.started":"2025-04-15T01:58:52.968256Z","shell.execute_reply":"2025-04-15T01:58:52.979966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One Hot Encoding data kategorikal non-ordinal\ndf_encoded = pd.get_dummies(df, columns=['merchant_type', 'device_type'], drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T01:58:52.981862Z","iopub.execute_input":"2025-04-15T01:58:52.982320Z","iopub.status.idle":"2025-04-15T01:58:53.000655Z","shell.execute_reply.started":"2025-04-15T01:58:52.982287Z","shell.execute_reply":"2025-04-15T01:58:52.999962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SMOTE untuk imbalance data\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\nX = df_encoded.drop(columns=['label', 'transaction_id','amount'])  # drop label dan ID, untuk amount pakai amount_log\ny = df_encoded['label']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n\n# SMOTE untuk data train\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T01:58:53.001641Z","iopub.execute_input":"2025-04-15T01:58:53.001898Z","iopub.status.idle":"2025-04-15T01:58:53.017550Z","shell.execute_reply.started":"2025-04-15T01:58:53.001876Z","shell.execute_reply":"2025-04-15T01:58:53.016856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training model XGBoost\nfrom xgboost import XGBClassifier\n\nmodel = XGBClassifier(scale_pos_weight=1, use_label_encoder=False, eval_metric='logloss')\nmodel.fit(X_res, y_res)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T01:58:53.018222Z","iopub.execute_input":"2025-04-15T01:58:53.018401Z","iopub.status.idle":"2025-04-15T01:58:53.080227Z","shell.execute_reply.started":"2025-04-15T01:58:53.018385Z","shell.execute_reply":"2025-04-15T01:58:53.079378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Pastikan data test (X_test dan y_test) belum tersentuh SMOTE\ny_pred = model.predict(X_test)\n\n# 1. Laporan Klasifikasi\nprint(\"üìä Classification Report:\\n\")\nprint(classification_report(y_test, y_pred, digits=4))\n\n# 2. Confusion Matrix\ncm = confusion_matrix(y_test, y_pred, labels=[0, 1])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Fraud\", \"Fraud\"])\n\n# 3. Tampilkan Confusion Matrix\nplt.figure(figsize=(6, 4))\ndisp.plot(cmap='Blues', values_format='d')\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T01:58:53.081059Z","iopub.execute_input":"2025-04-15T01:58:53.081265Z","iopub.status.idle":"2025-04-15T01:58:53.241639Z","shell.execute_reply.started":"2025-04-15T01:58:53.081247Z","shell.execute_reply":"2025-04-15T01:58:53.240844Z"}},"outputs":[],"execution_count":null}]}